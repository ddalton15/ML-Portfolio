{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae19c4df",
   "metadata": {},
   "source": [
    "# Simple Offline Single-Agent vs Multi-Agent (LangGraph + Ollama + Local Embeddings)\n",
    "\n",
    "This lesson demonstrates two ways to orchestrate LLM work:\n",
    "\n",
    "- **Single-agent**: one agent does everything end-to-end.\n",
    "- **Multi-agent**: multiple specialized agents collaborate (plan → retrieve → write).\n",
    "\n",
    "Everything runs **locally**:\n",
    "- **Ollama** runs the LLM on your machine (no cloud keys).\n",
    "- **sentence-transformers** generates embeddings locally.\n",
    "- **FAISS** performs local vector similarity search.\n",
    "\n",
    "**Sources**\n",
    "- [FAISS](https://faiss.ai/index.html)\n",
    "- [LangGraph/LangChain](https://www.langchain.com/langgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b097e6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip -q install -U langgraph langchain langchain-community langchain-text-splitters sentence-transformers faiss-cpu pandas langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb06d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import TypedDict, List\n",
    "from pathlib import Path\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa61518",
   "metadata": {},
   "source": [
    "## Step 1 — Load the dataset (CSV → Documents)\n",
    "\n",
    "[Data source](https://www.kaggle.com/datasets/sumitm004/arxiv-scientific-research-papers-dataset?resource=download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92ffe081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: data/arXiv_scientific_dataset.csv\n",
      "Rows: 3000 | Cols: 10\n",
      "Columns: ['id', 'title', 'category', 'category_code', 'published_date', 'updated_date', 'authors', 'first_author', 'summary', 'summary_word_count']\n",
      "Using text column: summary\n",
      "Missing summaries: 0\n",
      "Docs: 3000\n",
      "\n",
      "Example doc:\n",
      " Title: Dynamic Backtracking\n",
      "Abstract: Because of their occasional need to return to shallow points in a search\n",
      "tree, existing backtracking methods can sometimes erase meaningful progress\n",
      "toward solving a search problem. In this paper, we present a method by which\n",
      "backtrack points can be moved deeper in the search space, thereby avoiding this\n",
      "difficulty. The technique developed is a variant of dependency-directed\n",
      "backtracking that uses only polynomial space while still providing useful\n",
      "control in\n"
     ]
    }
   ],
   "source": [
    "CSV_PATH = Path(\"data/arXiv_scientific_dataset.csv\")\n",
    "print(\"Loading:\", CSV_PATH)\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Rows:\", len(df), \"| Cols:\", len(df.columns))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "TEXT_COL = \"summary\"\n",
    "print(\"Using text column:\", TEXT_COL)\n",
    "\n",
    "if TEXT_COL not in df.columns:\n",
    "    raise ValueError(f\"Missing '{TEXT_COL}' column\")\n",
    "\n",
    "print(\"Missing summaries:\", df[TEXT_COL].isna().sum())\n",
    "\n",
    "\n",
    "def row_to_text(r):\n",
    "    title = (\n",
    "        str(r[\"title\"])\n",
    "        if \"title\" in df.columns and pd.notna(r.get(\"title\", None))\n",
    "        else \"\"\n",
    "    )\n",
    "    body = str(r[TEXT_COL]) if pd.notna(r[TEXT_COL]) else \"\"\n",
    "    return f\"Title: {title}\\nAbstract: {body}\" if title else body\n",
    "\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=row_to_text(r), metadata={\"row\": int(i)})\n",
    "    for i, r in df.iterrows()\n",
    "]\n",
    "docs = [d for d in docs if d.page_content.strip()]\n",
    "print(\"Docs:\", len(docs))\n",
    "print(\"\\nExample doc:\\n\", docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df65071b",
   "metadata": {},
   "source": [
    "## Step 2 — Build a local retriever (Chunk → Embed → Index)\n",
    "\n",
    "A “retriever” finds the most relevant text passages for a question.\n",
    "\n",
    "We build it in three small steps:\n",
    "\n",
    "1. **Chunking**  \n",
    "   Split long text into overlapping passages. This improves retrieval accuracy and avoids losing context at boundaries.\n",
    "\n",
    "2. **Embeddings (local)**  \n",
    "   Convert each chunk into a vector using a local sentence-transformers model.\n",
    "\n",
    "3. **Vector index (FAISS)**  \n",
    "   Store vectors so we can efficiently run similarity search.\n",
    "\n",
    "Outputs of this step:\n",
    "- `retrieve(query, k)` returns top‑k relevant chunks\n",
    "- `evidence_block(...)` formats those chunks for the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06ff88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking documents...\n",
      "Chunks: 3040\n",
      "Example chunk:\n",
      " Title: Dynamic Backtracking\n",
      "Abstract: Because of their occasional need to return to shallow points in a search\n",
      "tree, existing backtracking methods can sometimes erase meaningful progress\n",
      "toward solving a search problem. In this paper, we present a method by which\n",
      "backtrack points can be moved deeper\n",
      "\n",
      "Loading embedding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1729.08it/s, Materializing param=pooler.dense.weight]                             \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model ready.\n",
      "\n",
      "Building FAISS index...\n",
      "FAISS index ready.\n"
     ]
    }
   ],
   "source": [
    "print(\"Chunking documents...\")\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=80)\n",
    "chunks = splitter.split_documents(docs)\n",
    "print(\"Chunks:\", len(chunks))\n",
    "print(\"Example chunk:\\n\", chunks[0].page_content[:300])\n",
    "\n",
    "print(\"\\nLoading embedding model...\")\n",
    "emb = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={\"device\": \"mps\"}\n",
    ")\n",
    "print(\"Embedding model ready.\")\n",
    "\n",
    "print(\"\\nBuilding FAISS index...\")\n",
    "vs = FAISS.from_documents(chunks, emb)\n",
    "print(\"FAISS index ready.\")\n",
    "\n",
    "\n",
    "def retrieve(query: str, k: int = 5) -> List[Document]:\n",
    "    print(f\"\\n[retrieve] Query: {query} | top_k={k}\")\n",
    "    results = vs.similarity_search(query, k=k)\n",
    "    print(\"[retrieve] Results:\", len(results))\n",
    "    return results\n",
    "\n",
    "\n",
    "def evidence_block(docs: List[Document]) -> str:\n",
    "    out = []\n",
    "    for d in docs:\n",
    "        rid = d.metadata.get(\"row\", \"?\")\n",
    "        txt = d.page_content.strip().replace(\"\\n\", \" \")\n",
    "        out.append(f\"[row={rid}] {txt[:900]}{' ...' if len(txt)>900 else ''}\")\n",
    "    return \"\\n\\n\".join(out) if out else \"(no matches)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af15ecf0",
   "metadata": {},
   "source": [
    "## Step 3 — Start a local LLM with Ollama\n",
    "\n",
    "We connect to a locally running Ollama model.\n",
    "\n",
    "This gives us a chat-style LLM we can call with:\n",
    "- a **system message** (rules like “use only evidence”)\n",
    "- a **user message** (question + retrieved evidence)\n",
    "\n",
    "[Ollama Quickstart Guide](https://docs.ollama.com/quickstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9351fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"ministral-3:8b\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f68dc4",
   "metadata": {},
   "source": [
    "# Demo A — Single-Agent Workflow (Retrieve → Answer)\n",
    "\n",
    "**What it is:**  \n",
    "A single node/agent does the entire job.\n",
    "\n",
    "**What happens:**\n",
    "1. Receive the user question.\n",
    "2. Retrieve relevant chunks from FAISS.\n",
    "3. Write the final answer using only those chunks.\n",
    "4. Cite sources as `[row=...]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a98c8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"What are the top 3 open problems in these papers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c7223b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class S(TypedDict, total=False):\n",
    "    question: str\n",
    "    final: str\n",
    "\n",
    "\n",
    "def single_node(state: S) -> S:\n",
    "    q = state[\"question\"]\n",
    "    ev = evidence_block(retrieve(q, k=5))\n",
    "    resp = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"Use ONLY the EVIDENCE. Cite as [row=...]. If evidence is weak, say so.\"\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=f\"QUESTION:\\n{q}\\n\\nEVIDENCE:\\n{ev}\\n\\nWrite a clear answer.\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return {**state, \"final\": resp.content}\n",
    "\n",
    "\n",
    "g1 = StateGraph(S)\n",
    "g1.add_node(\"single\", single_node)\n",
    "g1.set_entry_point(\"single\")\n",
    "g1.add_edge(\"single\", END)\n",
    "single_app = g1.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a66b7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[retrieve] Query: What are the top 3 open problems in these papers | top_k=5\n",
      "[retrieve] Results: 5\n",
      "Based **solely** on the provided evidence, here are the **top 3 open problems** identified or implied in the papers:\n",
      "\n",
      "1. **Automating Proofs for Heuristic Properties in Planning**\n",
      "   - **[row=2228]** The paper discusses that while the heuristic **h+** in classical planning shows remarkable properties (e.g., absence of local minima), these proofs are currently **hand-made**. The open question is whether **domain analysis techniques** can **automatically** derive such proofs, especially given earlier failures in scalable analysis methods.\n",
      "\n",
      "2. **Generalizing Difficulty Metrics for Complex Problems**\n",
      "   - **[row=2310]** While Sudoku difficulty metrics are evaluated, the paper suggests that **generalizing these metrics to other problems** (e.g., beyond Sudoku) remains an open challenge. Specifically, the **two sources of difficulty** (individual step complexity and dependency structure) must be further validated and adapted for broader applicability.\n",
      "\n",
      "3. **Unified Flaw Selection Strategies in Partial-Order Planning**\n",
      "   - **[row=80]** The paper compares **LCFR** and **ZLIFO** strategies for flaw selection in partial-order causal link (POCL) planning, noting conflicting claims about their effectiveness. The unresolved question is whether **a unified theoretical framework** can reconcile these strategies or identify **optimal hybrid approaches** that combine their strengths.\n",
      "\n",
      "---\n",
      "**Note on Weak Evidence:**\n",
      "- **[row=2876]** is too vague (\"emergence of flexible functions\") and lacks concrete open problems.\n",
      "- No direct open problems are explicitly stated in **[row=1120]**, only a description of an ASP competition.\n"
     ]
    }
   ],
   "source": [
    "single_out = single_app.invoke({\"question\": q})\n",
    "print(single_out[\"final\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfae835",
   "metadata": {},
   "source": [
    "# Demo B — Multi-Agent Workflow (Planner → Librarian → Writer → Reviewer → Finalizer)\n",
    "\n",
    "**What it is:**  \n",
    "A lightweight collaboration pattern where each agent has a single responsibility, and a reviewer enforces grounding and clarity.\n",
    "\n",
    "**Agents (nodes):**\n",
    "1. **Planner**\n",
    "   - Produces a short plan\n",
    "   - Proposes several retrieval queries (different angles on the question)\n",
    "\n",
    "2. **Librarian**\n",
    "   - Executes retrieval for each query against the FAISS index\n",
    "   - Consolidates the best chunks into one **evidence package** for the rest of the team\n",
    "\n",
    "3. **Writer**\n",
    "   - Writes a **draft** answer\n",
    "   - Uses only the consolidated evidence\n",
    "   - Adds citations like `[row=...]` and notes limitations if evidence is weak\n",
    "\n",
    "4. **Reviewer**\n",
    "   - Critiques the draft against the evidence\n",
    "   - Flags unsupported claims, missing citations, and missing trade-offs\n",
    "   - Outputs required edits (bullet list)\n",
    "\n",
    "5. **Finalizer**\n",
    "   - Applies the required edits to produce the final response\n",
    "   - Keeps the answer grounded in evidence and preserves citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63975d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class M(TypedDict, total=False):\n",
    "    question: str\n",
    "    plan: str\n",
    "    evidence: str\n",
    "    draft: str\n",
    "    review: str\n",
    "    final: str\n",
    "\n",
    "\n",
    "def planner(state: M) -> M:\n",
    "    q = state[\"question\"]\n",
    "    resp = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"Make a short plan and 5 short retrieval queries. Output as bullets.\"\n",
    "            ),\n",
    "            HumanMessage(content=q),\n",
    "        ]\n",
    "    )\n",
    "    return {**state, \"plan\": resp.content}\n",
    "\n",
    "\n",
    "def librarian(state: M) -> M:\n",
    "    lines = [\n",
    "        ln.strip(\"-•* \").strip()\n",
    "        for ln in state[\"plan\"].splitlines()\n",
    "        if ln.strip().startswith((\"-\", \"•\", \"*\"))\n",
    "    ]\n",
    "    queries = lines[:3] if lines else [state[\"question\"]]\n",
    "\n",
    "    retrieved = []\n",
    "    for qu in queries:\n",
    "        retrieved += retrieve(qu, k=3)\n",
    "\n",
    "    ev = evidence_block(retrieved[:8])\n",
    "    return {**state, \"evidence\": ev}\n",
    "\n",
    "\n",
    "def writer(state: M) -> M:\n",
    "    resp = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"Use ONLY the EVIDENCE. Cite as [row=...]. Provide trade-offs and limitations.\"\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=(\n",
    "                    f\"QUESTION:\\n{state['question']}\\n\\n\"\n",
    "                    f\"PLAN:\\n{state['plan']}\\n\\n\"\n",
    "                    f\"EVIDENCE:\\n{state['evidence']}\\n\\n\"\n",
    "                    \"Write a DRAFT answer.\"\n",
    "                )\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return {**state, \"draft\": resp.content}\n",
    "\n",
    "\n",
    "def reviewer(state: M) -> M:\n",
    "    resp = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=(\n",
    "                    \"You are a strict reviewer. Check the DRAFT against the EVIDENCE.\\n\"\n",
    "                    \"Flag: unsupported claims, missing citations, weak structure, missing trade-offs.\\n\"\n",
    "                    \"Return:\\n\"\n",
    "                    \"1) REVIEW (short)\\n\"\n",
    "                    \"2) REQUIRED_EDITS (bullets)\\n\"\n",
    "                )\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=(\n",
    "                    f\"QUESTION:\\n{state['question']}\\n\\n\"\n",
    "                    f\"EVIDENCE:\\n{state['evidence']}\\n\\n\"\n",
    "                    f\"DRAFT:\\n{state['draft']}\\n\"\n",
    "                )\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return {**state, \"review\": resp.content}\n",
    "\n",
    "\n",
    "def finalizer(state: M) -> M:\n",
    "    resp = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"Revise the DRAFT using the REQUIRED_EDITS. Stay grounded in the EVIDENCE and keep citations [row=...].\"\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=(\n",
    "                    f\"EVIDENCE:\\n{state['evidence']}\\n\\n\"\n",
    "                    f\"DRAFT:\\n{state['draft']}\\n\\n\"\n",
    "                    f\"REVIEW:\\n{state['review']}\\n\\n\"\n",
    "                    \"Return the FINAL answer.\"\n",
    "                )\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return {**state, \"final\": resp.content}\n",
    "\n",
    "\n",
    "g2 = StateGraph(M)\n",
    "g2.add_node(\"planner\", planner)\n",
    "g2.add_node(\"librarian\", librarian)\n",
    "g2.add_node(\"writer\", writer)\n",
    "g2.add_node(\"reviewer\", reviewer)\n",
    "g2.add_node(\"finalizer\", finalizer)\n",
    "\n",
    "g2.set_entry_point(\"planner\")\n",
    "g2.add_edge(\"planner\", \"librarian\")\n",
    "g2.add_edge(\"librarian\", \"writer\")\n",
    "g2.add_edge(\"writer\", \"reviewer\")\n",
    "g2.add_edge(\"reviewer\", \"finalizer\")\n",
    "g2.add_edge(\"finalizer\", END)\n",
    "\n",
    "multi_app = g2.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6d17341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[retrieve] Query:  | top_k=3\n",
      "[retrieve] Results: 3\n",
      "\n",
      "[retrieve] Query: Theoretical depth (e.g., P vs. NP variants). | top_k=3\n",
      "[retrieve] Results: 3\n",
      "\n",
      "[retrieve] Query: Practical relevance (e.g., scalability, real-world applications). | top_k=3\n",
      "[retrieve] Results: 3\n",
      "Here is the revised **DRAFT** incorporating the **REQUIRED_EDITS**, grounded in the **EVIDENCE**, and addressing trade-offs and limitations explicitly:\n",
      "\n",
      "---\n",
      "\n",
      "### **Top 3 Open Problems in AI/CS Research**\n",
      "*(Ranked by theoretical/practical significance, with cross-referenced evidence and trade-offs)*\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Scalability of Probabilistic Planning in Uncertain Domains**\n",
      "**Evidence Base**:\n",
      "- **[row=1470]**: *\"Many problems of interest are complete for PP and NP^PP... deserving of additional study.\"*\n",
      "- **[row=1965]**: Sudoku-like CSPs (NP-complete) serve as analogs for probabilistic planning complexity.\n",
      "\n",
      "**Open Problem**:\n",
      "While probabilistic planning (e.g., finding small plans in noisy environments) is **PP-hard** (a probabilistic complexity class), **no scalable algorithms exist for large-scale domains** (e.g., >1000 probabilistic states). The theoretical hardness (PP-completeness) contrasts with practical needs in robotics or logistics, where approximate solutions are often required.\n",
      "\n",
      "**Trade-offs**:\n",
      "- **Theoretical vs. Practical**:\n",
      "  - PP-hardness implies no exact polynomial-time solutions exist, but **heuristic methods** (e.g., Monte Carlo Tree Search or probabilistic model checking tools like PRISM) may offer near-optimal plans for bounded domains.\n",
      "  - **Trade-off**: Plan quality vs. computational cost remains unresolved for domains with high state spaces.\n",
      "- **Representation Overhead**:\n",
      "  - Succinct probabilistic representations (e.g., Bayesian networks) may not scale with problem size, as noted in [row=1470].\n",
      "\n",
      "**Limitations**:\n",
      "- **No known polynomial-time reductions** to NP/co-NP for probabilistic planning, limiting theoretical progress.\n",
      "- **Empirical gaps**: While [row=1470] highlights complexity, real-world applications lack validated scalable approximations (e.g., how do heuristic methods perform on domains with >1000 states?).\n",
      "- **Analogies**: The NP-hardness of Sudoku-like CSPs in [row=1965] suggests that approximate resolution theories (e.g., \"approximating\" CSPs with resolution rules) could inspire hybrid methods for probabilistic planning.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Designing Intuitive GUIs for Non-Expert Proof Assistants**\n",
      "**Evidence Base**:\n",
      "- **[row=488]**: *\"The evaluation of the experiment provides insights for the interaction design for non-expert users... but lacks scalability data.\"*\n",
      "- **[row=13]**: Random-worlds method offers a theoretical framework for reasoning under uncertainty (though not directly applicable to proof assistants).\n",
      "\n",
      "**Open Problem**:\n",
      "Current proof assistants (e.g., Coq, Lean) are optimized for experts, but **no unified GUI framework exists for non-experts** to construct proofs intuitively. The [row=488] experiment shows that students (non-experts) struggle with proof sketching, yet no scalable solution addresses this gap.\n",
      "\n",
      "**Trade-offs**:\n",
      "- **Usability vs. Rigor**:\n",
      "  - Simplified interfaces (e.g., auto-filling proof steps) may sacrifice formal correctness, as noted in [row=488], where students preferred manual sketching for clarity.\n",
      "  - **Trade-off**: Automation (e.g., guided proof steps) vs. user control (e.g., manual intervention) remains unresolved.\n",
      "- **Domain-Specific Needs**:\n",
      "  - Solutions may require tailored designs per field (e.g., mathematical proofs vs. software verification), limiting generalizability.\n",
      "\n",
      "**Limitations**:\n",
      "- **Empirical Gaps**: The [row=488] experiment is small-scale; how do these findings generalize to broader user populations?\n",
      "- **Theoretical Limits**: While [row=13]’s random-worlds method provides a theoretical framework for reasoning under uncertainty, it does not directly address the GUI design problem for proof assistants.\n",
      "- **Prior Art Ignored**: The draft conflates unrelated domains (e.g., [row=1323]’s decision-theoretic advertising) with proof assistants. No prior work bridges these gaps.\n",
      "\n",
      "**Potential Synthesis**:\n",
      "- **Hybrid Approaches**: Combine heuristic proof guidance (e.g., [row=488]’s manual sketching) with theoretical frameworks (e.g., [row=13]’s random-worlds) to create adaptive GUIs.\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Theoretical and Practical Limits of Information Compression via Multiple Alignment**\n",
      "**Evidence Base**:\n",
      "- **[row=2297]**: Claims multiple alignment may enable universal compression, but lacks proof for arbitrary data.\n",
      "- **[row=1965]**: Sudoku-like CSPs are NP-hard, suggesting alignment may not scale for complex structures.\n",
      "- **[Citation Needed]**: Shannon’s entropy bounds and Kolmogorov complexity provide counterexamples to universal compression.\n",
      "\n",
      "**Open Problem**:\n",
      "The claim that **multiple alignment enables universal information compression** (e.g., [row=2297]) remains **unproven** for arbitrary data. While alignment may compress structured data (e.g., biological sequences), its applicability to unstructured or random data is unclear.\n",
      "\n",
      "**Trade-offs**:\n",
      "- **Compression vs. Semantic Loss**:\n",
      "  - Alignment may compress data but risks losing semantic structure (e.g., natural language vs. biological sequences).\n",
      "  - **Trade-off**: Compression efficiency vs. interpretability of compressed data.\n",
      "- **Algorithmic Limits**:\n",
      "  - NP-hardness of alignment (e.g., [row=1965]’s Sudoku puzzles) may preclude scalable solutions for complex domains.\n",
      "\n",
      "**Limitations**:\n",
      "- **Theoretical Gaps**: No proof exists that multiple alignment can compress *all* data types optimally (e.g., random strings defy compression).\n",
      "- **Practical Challenges**:\n",
      "  - Designing alignment rules for arbitrary data types remains an open problem.\n",
      "  - **Counterexamples**: Shannon’s entropy bounds and Kolmogorov complexity suggest that not all data benefit from alignment-based compression.\n",
      "- **Empirical Validation Missing**: While [row=2297] posits alignment as a universal tool, no empirical validation exists for its scalability or robustness.\n",
      "\n",
      "**Potential Synthesis**:\n",
      "- **Domain-Specific Solutions**: Focus on structured data (e.g., genomics) where alignment is effective, rather than claiming universality.\n",
      "- **Hybrid Methods**: Combine alignment with other compression techniques (e.g., entropy coding) to address semantic loss.\n",
      "\n",
      "---\n",
      "\n",
      "### **Cross-Cutting Limitations**\n",
      "*(Tied to Specific Papers and Actionable Syntheses)*\n",
      "\n",
      "1. **Lack of Unifying Frameworks**:\n",
      "   - **Evidence**: [row=2738]’s *Ω*-units remain untested in practice despite their theoretical potential to bridge probabilistic planning and proof assistants.\n",
      "   - **Actionable Gap**: How can *Ω*-units be adapted to address the scalability of probabilistic planning or non-expert proof assistants?\n",
      "\n",
      "2. **Representation Constraints**:\n",
      "   - **Evidence**:\n",
      "     - [row=2548]’s DSNS assumes real-number attributes, limiting applicability to discrete domains.\n",
      "     - [row=1965]’s CSPs are discrete, raising questions about how to reconcile these approaches.\n",
      "   - **Actionable Gap**: Develop hybrid representations (e.g., probabilistic CSPs) that leverage strengths of both continuous and discrete methods.\n",
      "\n",
      "3. **Empirical vs. Theoretical Disconnect**:\n",
      "   - **Evidence**:\n",
      "     - [row=488]’s experiment is small-scale, while [row=1470]’s PP-hardness is theoretical.\n",
      "     - [row=2297]’s alignment claims lack empirical validation.\n",
      "   - **Actionable Gap**: Design large-scale experiments to validate theoretical claims (e.g., test alignment on diverse datasets).\n",
      "\n",
      "---\n",
      "**Final Answer**:\n",
      "The top 3 open problems are:\n",
      "1. **Scalable probabilistic planning**: PP-hardness limits exact solutions, but heuristic methods (e.g., PRISM) offer near-optimal approximations for bounded domains. The trade-off between plan quality and computational cost remains unresolved for large-scale systems.\n",
      "2. **Non-expert-friendly proof assistants**: GUI designs lack empirical validation for broad adoption, with trade-offs between automation and user control. Hybrid approaches (e.g., combining heuristic guidance with theoretical frameworks) are needed.\n",
      "3. **Universal information compression via multiple alignment**: The theoretical claim remains unproven for arbitrary data, with trade-offs between compression efficiency and semantic loss. Domain-specific solutions and hybrid methods are required.\n",
      "\n",
      "**Key Limitations**:\n",
      "- **Theoretical vs. Practical**: Gaps between PP-hardness and scalable heuristics, or alignment universality and empirical validation.\n",
      "- **Domain Specificity**: Solutions for probabilistic planning, proof assistants, and alignment must address unique constraints (e.g., real-number vs. discrete representations).\n",
      "- **Unified Frameworks**: Tools like *Ω*-units [row=2738] remain untested, limiting cross-domain progress.\n",
      "\n",
      "**Actionable Next Steps**:\n",
      "- Validate theoretical claims with large-scale experiments (e.g., test alignment on diverse datasets).\n",
      "- Develop hybrid representations (e.g., probabilistic CSPs) to bridge continuous and discrete methods.\n",
      "- Explore *Ω*-units’ applicability to scalable probabilistic planning or non-expert proof assistants.\n"
     ]
    }
   ],
   "source": [
    "multi_out = multi_app.invoke({\"question\": q})\n",
    "print(multi_out[\"final\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
