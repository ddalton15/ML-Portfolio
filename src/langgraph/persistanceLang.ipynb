{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5789bc3-b1ae-42c7-94a8-2ef4f89946fc",
   "metadata": {},
   "source": [
    "# Lesson 4: Persistence and Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "440ff6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "get_current_weather\n"
     ]
    }
   ],
   "source": [
    "WMO_CODES = {\n",
    "    0: \"Clear sky\", 1: \"Mainly clear\", 2: \"Partly cloudy\", 3: \"Overcast\",\n",
    "    45: \"Foggy\", 48: \"Icy fog\",\n",
    "    51: \"Light drizzle\", 53: \"Moderate drizzle\", 55: \"Dense drizzle\",\n",
    "    61: \"Slight rain\", 63: \"Moderate rain\", 65: \"Heavy rain\",\n",
    "    71: \"Slight snow\", 73: \"Moderate snow\", 75: \"Heavy snow\",\n",
    "    80: \"Slight showers\", 81: \"Moderate showers\", 82: \"Violent showers\",\n",
    "    95: \"Thunderstorm\", 99: \"Thunderstorm with hail\",\n",
    "}\n",
    "\n",
    "@tool\n",
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Get the current weather for a given location.\"\"\"\n",
    "    # Step 1: geocode city name -> lat/lon\n",
    "    geo = requests.get(\n",
    "        \"https://geocoding-api.open-meteo.com/v1/search\",\n",
    "        params={\"name\": location, \"count\": 1},\n",
    "        timeout=10,\n",
    "    )\n",
    "    geo.raise_for_status()\n",
    "    results = geo.json().get(\"results\")\n",
    "    if not results:\n",
    "        return f\"Could not find location: {location}\"\n",
    "    place = results[0]\n",
    "    lat, lon, name = place[\"latitude\"], place[\"longitude\"], place[\"name\"]\n",
    "\n",
    "    # Step 2: fetch current conditions\n",
    "    weather = requests.get(\n",
    "        \"https://api.open-meteo.com/v1/forecast\",\n",
    "        params={\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "            \"current\": \"temperature_2m,apparent_temperature,relative_humidity_2m,weather_code,wind_speed_10m\",\n",
    "            \"temperature_unit\": \"fahrenheit\",\n",
    "            \"wind_speed_unit\": \"mph\",\n",
    "            \"timezone\": \"auto\",\n",
    "        },\n",
    "        timeout=10,\n",
    "    )\n",
    "    weather.raise_for_status()\n",
    "    c = weather.json()[\"current\"]\n",
    "\n",
    "    condition = WMO_CODES.get(c[\"weather_code\"], f\"Code {c['weather_code']}\")\n",
    "    return (\n",
    "        f\"Location: {name}\\n\"\n",
    "        f\"Temperature: {c['temperature_2m']}°F\\n\"\n",
    "        f\"Feels like: {c['apparent_temperature']}°F\\n\"\n",
    "        f\"Condition: {condition}\\n\"\n",
    "        f\"Humidity: {c['relative_humidity_2m']}%\\n\"\n",
    "        f\"Wind: {c['wind_speed_10m']} mph\"\n",
    "    )\n",
    "\n",
    "tool = get_current_weather\n",
    "print(type(tool))\n",
    "print(tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c033522-d2fc-41ac-8e3c-5e35872bf88d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 574
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            # Ollama sometimes wraps arg values as {'description': ..., 'value': ...}\n",
    "            args = {\n",
    "                k: v['value'] if isinstance(v, dict) and 'value' in v else v\n",
    "                for k, v in t['args'].items()\n",
    "            }\n",
    "            result = self.tools[t['name']].invoke(args)\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOllama(model=\"lfm2.5-thinking\", temperature=0.7)\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in seattle for today?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "714d1205-f8fc-4912-b148-2a45da99219c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'lfm2.5-thinking', 'created_at': '2026-02-16T15:58:45.509941Z', 'done': True, 'done_reason': 'stop', 'total_duration': 646022292, 'load_duration': 36153084, 'prompt_eval_count': 149, 'prompt_eval_duration': 38153667, 'eval_count': 127, 'eval_duration': 553375375, 'logprobs': None, 'model_name': 'lfm2.5-thinking', 'model_provider': 'ollama'}, id='lc_run--019c672c-f279-7462-a1ca-4c6d73aac7ff-0', tool_calls=[{'name': 'get_current_weather', 'args': {'location': 'Seattle'}, 'id': '23d3c4f2-c151-4739-bce8-2927fa88c87a', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 149, 'output_tokens': 127, 'total_tokens': 276})]\n",
      "Calling: {'name': 'get_current_weather', 'args': {'location': 'Seattle'}, 'id': '23d3c4f2-c151-4739-bce8-2927fa88c87a', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='Location: Seattle\\nTemperature: 33.3°F\\nFeels like: 27.3°F\\nCondition: Overcast\\nHumidity: 94%\\nWind: 4.8 mph', name='get_current_weather', tool_call_id='23d3c4f2-c151-4739-bce8-2927fa88c87a')]\n",
      "[AIMessage(content='The current weather in Seattle is **33.3°F** with an **Overcast** condition. The feeling temperature is **27.3°F**, humidity is **94%**, and wind speed is **4.8 mph**. Let me know if you need further details!', additional_kwargs={}, response_metadata={'model': 'lfm2.5-thinking', 'created_at': '2026-02-16T15:58:50.168744Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2734671916, 'load_duration': 34310833, 'prompt_eval_count': 222, 'prompt_eval_duration': 63986500, 'eval_count': 569, 'eval_duration': 2553815628, 'logprobs': None, 'model_name': 'lfm2.5-thinking', 'model_provider': 'ollama'}, id='lc_run--019c672c-fc89-7052-b5ec-74477dd6da1c-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 222, 'output_tokens': 569, 'total_tokens': 791})]\n"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'lfm2.5-thinking', 'created_at': '2026-02-16T15:58:51.862406Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1684480875, 'load_duration': 31213167, 'prompt_eval_count': 295, 'prompt_eval_duration': 32284125, 'eval_count': 355, 'eval_duration': 1559943697, 'logprobs': None, 'model_name': 'lfm2.5-thinking', 'model_provider': 'ollama'}, id='lc_run--019c672d-0740-73f0-969b-bac3d9ba6095-0', tool_calls=[{'name': 'get_current_weather', 'args': {'location': 'Los Angeles'}, 'id': 'dccda08b-3eb4-48c4-90dd-da69744497e6', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 295, 'output_tokens': 355, 'total_tokens': 650})]}\n",
      "Calling: {'name': 'get_current_weather', 'args': {'location': 'Los Angeles'}, 'id': 'dccda08b-3eb4-48c4-90dd-da69744497e6', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='Location: Los Angeles\\nTemperature: 54.2°F\\nFeels like: 49.3°F\\nCondition: Overcast\\nHumidity: 83%\\nWind: 11.1 mph', name='get_current_weather', tool_call_id='dccda08b-3eb4-48c4-90dd-da69744497e6')]}\n",
      "{'messages': [AIMessage(content='The current weather in Los Angeles is **54.2°F** with an **Overcast** condition. The feels-like temperature is **49.3°F**, humidity is **83%**, and wind speed is **11.1 mph**. Let me know if you need more details!', additional_kwargs={}, response_metadata={'model': 'lfm2.5-thinking', 'created_at': '2026-02-16T15:58:55.917991Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2252980375, 'load_duration': 36579334, 'prompt_eval_count': 369, 'prompt_eval_duration': 59430916, 'eval_count': 476, 'eval_duration': 2061102455, 'logprobs': None, 'model_name': 'lfm2.5-thinking', 'model_provider': 'ollama'}, id='lc_run--019c672d-14e0-7b92-8690-97c984944ebe-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 369, 'output_tokens': 476, 'total_tokens': 845})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What about in la?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content=\"The current weather in **Los Angeles** (54.2°F) is warmer than in **Seattle** (33.3°F). Los Angeles is significantly warmer despite similar overcast conditions. Let me know if you'd like further details!\", additional_kwargs={}, response_metadata={'model': 'lfm2.5-thinking', 'created_at': '2026-02-16T15:58:57.36343Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1435962500, 'load_duration': 28638500, 'prompt_eval_count': 444, 'prompt_eval_duration': 32968250, 'eval_count': 289, 'eval_duration': 1273867793, 'logprobs': None, 'model_name': 'lfm2.5-thinking', 'model_provider': 'ollama'}, id='lc_run--019c672d-1db6-7c82-977e-d6c332b9a464-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 444, 'output_tokens': 289, 'total_tokens': 733})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "772bf2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'lfm2.5-thinking', 'created_at': '2026-02-16T16:00:24.978111Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4844179208, 'load_duration': 36415708, 'prompt_eval_count': 519, 'prompt_eval_duration': 150888250, 'eval_count': 1008, 'eval_duration': 4449358513, 'logprobs': None, 'model_name': 'lfm2.5-thinking', 'model_provider': 'ollama'}, id='lc_run--019c672e-66a3-7112-a1f3-f02400fffc21-0', tool_calls=[{'name': 'get_current_weather', 'args': {'location': 'Seville'}, 'id': '0f373804-8df0-4af1-807d-70b052d64072', 'type': 'tool_call'}, {'name': 'get_current_weather', 'args': {'location': 'Los Angeles'}, 'id': 'fcb44f40-6e5c-48fc-85fc-7f1a438081cf', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 519, 'output_tokens': 1008, 'total_tokens': 1527})]}\n",
      "Calling: {'name': 'get_current_weather', 'args': {'location': 'Seville'}, 'id': '0f373804-8df0-4af1-807d-70b052d64072', 'type': 'tool_call'}\n",
      "Calling: {'name': 'get_current_weather', 'args': {'location': 'Los Angeles'}, 'id': 'fcb44f40-6e5c-48fc-85fc-7f1a438081cf', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='Location: Seville\\nTemperature: 63.4°F\\nFeels like: 60.5°F\\nCondition: Partly cloudy\\nHumidity: 58%\\nWind: 5.7 mph', name='get_current_weather', tool_call_id='0f373804-8df0-4af1-807d-70b052d64072'), ToolMessage(content='Location: Los Angeles\\nTemperature: 53.8°F\\nFeels like: 48.5°F\\nCondition: Moderate rain\\nHumidity: 84%\\nWind: 12.1 mph', name='get_current_weather', tool_call_id='fcb44f40-6e5c-48fc-85fc-7f1a438081cf')]}\n",
      "{'messages': [AIMessage(content=\"Seville is warmer than Los Angeles today, with a temperature of **63.4°F** compared to Los Angeles' **53.8°F**. If you're considering a first-time homebuyer, Seville's milder climate and similar overcast conditions could make it a comfortable choice for initial living conditions. Let me know if you'd like further guidance!\", additional_kwargs={}, response_metadata={'model': 'lfm2.5-thinking', 'created_at': '2026-02-16T16:00:32.745669Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3973335625, 'load_duration': 38378084, 'prompt_eval_count': 665, 'prompt_eval_duration': 80552666, 'eval_count': 813, 'eval_duration': 3580415667, 'logprobs': None, 'model_name': 'lfm2.5-thinking', 'model_provider': 'ollama'}, id='lc_run--019c672e-8863-75b1-a6b5-6a3b0d0d8829-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 665, 'output_tokens': 813, 'total_tokens': 1478})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one would you recommend for a beginner first-time homebuyer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
